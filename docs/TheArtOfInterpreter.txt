
The Art of the Interpreter or, The Modularity Complex (Parts Zero, One, and Two)

by
Guy Lewis Steele Jr. and Gerald Jay Susman

May 1978


Abstract:
We examine the effects of various language design decisions on the programming styles available to a user of the language, with particular emphasis on the ability to incrementally construct modular systems. At each step we exhibit an interactive meta-circular interpreter for the language under consideration. Each new interpreter is the result of an incremental change to a previous interpreter.
We explore the consequences of various variable binding disciplines a n dt h e introduction of side effects. We find that dynamic scoping is unsuitable for constructing procedural abstractions, but has another role as an agent of modularity, being a structured form of side effect.
More general side effects are also found to be necessary to promote modular style. We find that the notion of side effect and the notion of equality (object identity) are mutually constraining; to define one is to define the other.
The interpreters we exhibit are all written in a simple dialect of LISP, and all implement LISP-like languages. A subset of these interpreters constitute a partial historical reconstruction of the actual evolution of LISP.

Keywords: abstraction, actors, applicative order, bindings, control structures, debugging, dynamic scoping, environments, fluid variables, FUNARG problem, functional objects, interactive programming, lambda-calculus, lexical scoping, LISP, modularity, procedural data, recursion equations, referential transparency, SCHEME, side effects, static scoping, structured programming

This report describes research
done at the Artificial Intelligence Laboratory of the Nassachusetts Institute of Technology. Support for the laboratory's artificial intelligence research is provided in part by the Advanced Research Projects Agency of the Department of Defense under Office of Naval Research contract N00014-75-C-0643.


Contents
Introduction
	Modularity
	LISP-like Languages
	Structure of the Paper
Part Zero - LISP and Interpreters
	Recursion Equations
	An Interpreter for LISP Recursion Equations
Part One - Variable Scoping Disciplines
	Procedures as Data
	Local Procedures
	Lexical Scoping
	Top Levels versus Referential Transparency
Part Two - State
	Decomposition of State
	Side Effects and Local State
	Side Effects in the Interpreter
	Equipotency of SETQ and RPLACA
	Side Effects and Equality
	Dynamic Scoping as a State-Decomposition Discipline
Summary
Acknowledgements
Notes
	{Can George do Better?}
	{Debugging}
	{Driver Loop with Side Effects}
	{EVALQUOTE }
	{Gaussian}
	{LABELS}
	{LABELS with Side Effects} *
	{Primitive Operators}
	{PROGN Wizardry )
	{QUOTE Mapping}
	{QUOTE Shafts the Compiler}
	{RPLACA Can Alter CAR Instead}
	{S-expression Postulates and Notation}
	{This ain't A-lists}
	{Value Quibble}
	{Weber}
	{Y-operator}
References





# Introduction

## Modularity

The entities constructed by programming are extremely complex. Accurate construction of large programs would be impossible without specific techniques for controlling this complexity. Most such techniques are based on finding ways to decompose a problem into almost independently surprobelm uber ene, loring i erase to onc surat mes are solved, the programmer must be able to combine the solutions with a minimum of unanticipated interactions. To the extent that a decomposition succeeds i n breaking a programming problem into manageable pieces, we say that the resulting program is modular; each part of the solution is called a module. Well-designed programming languages provide features which support the construction of modular programs.
One decomposition strategy is the packaging of common patterns of the use of a language. For example, in Algol a for loop captures a common pattern of if and goto statements. Packages of common patterns are not necessarily merely abbreviations to save typing. While a simple abbreviation has little abstraction power because a user must know what the abbreviation expands into, a good package encapsulates a higher level concept which has meaning independent of its implementation. Once a package is constructed the programmer can use it directly, without regard for the details it contains, precisely because it corresponds to a single notion he uses in dealing with the programming problem.
A package is most useful if its behavior is independent of the context of its use, thus reducing possible interference with other packages. package is called referentially transparent. Intuitively, referential transparency requires that the meanings of parts of a program be apparent and not change, so that such meanings can be reliably depended upon. In particular, names internal to one module should not affect or be affected by other modules - the external behavior of a module should be independent of the choice of names for its local identifiers.
To make a modular program , it is often necessary to think of a computational process as having state. In such cases, if the state can be naturally divided into independent parts, an important decomposition may be the division of the program into pieces which separately deal with the parts of the state.
We will discuss various stylistic techniques for achieving modularity. One would expect these techniques to complement each other. We will instead discover that they can come into conflict. Pushing one to an extreme in a language can seriously compromise others.



## LISP-like Languages 

Of the hundreds or thousands of computer languages which have been invented, there is one particular family of languages whose common ancestor was the original LISP, developed by McCarthy and others in the late 1950's. [LISP History] These languages are generally characterized by a simple, fully parenthesized ("Cambridge Polish") syntax; the ability to manipulate general, linked-list data structures; a standard representation for programs of the language in terms of these structures; and an interactive programming system based on an interpreter for the standard representation. Examples of such languages are LISP 1.5 [LISP 1.5M], MacLISP [Moon], InterLISP [Teitelman], CONNIVER [McDermott and Sussman], QA4 [Rulifson], PLASMA [Smith and Hewitt] [Hewitt and Smith], and SCHEME [SCHEME] [Revised Report]. We will call this family the LISP-like languages. 
The various members of this family differ in some interesting and often subtle ways. These differences have a profound impact on the styles of programming each may encourage or support. We will explore some of these differences by examining a series of small ("toy") evaluators which exhibit these differences without the clutter of "extra features" provided in real, production versions of LISP-like language systems. 
The series of evaluators to be considered partially constitute a reconstruction of what we believe to be the paths along which the family evolved. These paths can be explained after the be explained after the fact by viewing the historical changes to the language as being guided by the requirements of various aspects of modularity. 


## Structure of the Paper

Our discussion is divided into several parts, which form a linear progression. In addition, there are numerous large digressions which explore interesting side developments. These digressions are placed at the end as notes, cross-referenced to and from the text.
We exhibit a large number of LISP interpreters whose code differs from one to another in small ways (though their behavior differs greatly!). to avoid writing identical pieces of code over and over, each figure exhibits only routines which differ, and also contains cross-references to preceding figures from which missing routines for that figure are to be drawn.
Part Zero introduces the restricted dialect of the LISP language in which most of our examples are written. It also discusses the basic structure of an interpreter, and exhibits a meta-circular interpreter for the language.
Part One introduces procedural data as an abstraction mechanism, and considers its impact on variable scoping disciplines in the language. We are forced through a series of such disciplines as unexpected interactions are uncovered and fixed. Interpreters are exhibited for dynamic scoping and lexical scoping.
Part Two considers the problems associated with the decomposition of state. Side effects are introduced as a mechanism for effecting such decompositions. We find that the notion of side effect is inextricably wound up with the notion of identity. Dynamic scoping is retrospectively viewed as a restricted kind of side effect. 
With this we summarize and conclude with many tantalizing questions yet unanswered. 
In Part Three (in a separate paper) we will find that the introduction of side effects forces the issue of the order of evaluation of expressions. We will contrast call-by-name and its variants with call-by-value, and discuss how these control disciplines arise as a consequence of different models of packaging. In particular, call-by-name arises naturally from the syntactic nature of the Algol 60 copy rule. As before, many little interpreters for these disciplines will be exhibited. 
In Part Four we will be led to generalize the notion of a syntactic package. We will discuss meta-procedures, which deal with the representations of procedures. The distinction between a procedure and its representation will be more carefully considered. Macro processors, algebraic simplifiers, and compilers will be considered as meta-procedures. Various interpreters, compilers, and simplifiers will be exhibited. 




# Part Zero LISP and Interpreters 

## Recursion Equations

Contrary to popular belief, LISP was not originally derived from Church's X-calculus [Church] [LISP History]. The earliest LISP did not have a well-defined notion of free variables or procedural objects. Early LISP programs were similar to recursion equations, defining functions on symbolic expressions ("S-expressions"). They differed from the equations of pure recursive function theory [Kleene] by introducing the conditional expression construction (often called the "McCarthy conditional"), to avoid "pattern-directed invocation". That is, in recursive function theory one would define the factorial function by the following two equations: 

factorial(0) = 1 
factorial(successor(x)) = successor(x)*factorial(x) 

In early LISP, however, one would have written: 

factorial[x] = [x=0 → 1; T→ x*factorial[x-1]] 

where "[a → b; T→ c]" essentially means "if a then b else c". The recursive function theory version depends on selecting which of two equations to use by matching the argument to the left-hand sides (such a discipline is actually used in the PROLOG language [Warren]); the early LISP version represents this decision as a conditional expression. 
The theory of recursion equations deals with functions over the natural numbers. In LISP, however, one is interested in being able to manipulate algebraic expressions, programs, and other symbolic expressions as data structures. While such expressions can be encoded as numbers (using the technique of "arithmetization" developed by Kurt Gödel), such an encoding is not very convenient. Instead, a new kind of data called "S-expressions" (for "symbolic expressions") is introduced specifically to provide convenient encodings. S-expressions can be defined by a set of formal inductive axioms analogous to the Peano postulates used to define natural numbers. Here we will give only an informal and incomplete definition of S-expressions; for a more complete description, see (Note S-expression Postulates and Notation). 
For our purposes we will need only the special cases of S-expressions called atoms and lists. An atom is an "indivisible" data object, which we denote by writing a string of letters and digits; if only digits are used, then the atom is considered to be a number. Many special characters such as "-" and "+" are considered to be letters; we will see below that it is not necessary to specially reserve them 
them for for use as operator symbols. A list is a (possibly empty) sequence of S-expressions, notated by writing the S-expressions in order, between a set of parentheses and separated by spaces. A list of the atoms "FOO", "43", and "BAR" would be written "(FOO 43 BAR)". Notice that the definition of a list is recursive. For example, 

(DEFINE (SECOND X) (CAR (CDR X))) 

is a list of three things: the atomic symbol DEFINE, a list of the two atomic symbols SECOND and x, and another list of two other things. 
We can use S-expressions to represent algebraic expressions by using "Cambridge Polish" notation, essentially a parenthesized version of prefix Polish notation. Numeric constants are encoded as numeric atoms; variables are encoded as non-numeric atoms (which henceforth we will call atomic symbols); and procedure invocations are encoded as lists, where the first element of the list represents the procedure and the rest represent the arguments. For example, the algebraic expression "a*b+c*d" can be represented as "(+ (* a b) (* c d))". Notice that LISP does not need the usual precedence rules concerning whether multiplication or addition is performed first; the parentheses explicitly define the order. Also, all procedure invocations have a uniform syntax, no matter how many arguments are involved. Infix, superscript, and subscript notations are not used; thus the expression "Jp(x^2+1)" would be written "(J p (+ (* × 2) 1))". 
To encode a conditional expression 

[p_1 → e_1; p_2 → e_2; ... ; p_N → e_N]

(which means to evaluate the predicates p_j in order until a in order until a true one is found, at which point the value of e_j is taken to be the value of the conditional) we write the S-expression

(COND (P1 e1) (p2 e2) ... (pn en))

We can now encode sets of LISP recursion equations as S-expressions. For the equation 

factorial[x] = [x=0 → 1; T→ x*factorial[x-1]]

we write the S-expression

(DEFINE (FACTORIAL X)
           (COND ((= X 0) 1)
                 (T (* X (FACTORIAL ( X 1))))))


(We could also have written 

(DEFINE (FACTORIAL X) (COND ((=
X 0) 1) (T (* X (FACTORIAL (- X
1))))))

but we conventionally lay out S-expressions so that they are easy to read.) 
We now have a complete encoding for algebraic expressions and LISP recursion equations in the form of S-expressions. Suppose that we now want to write a LISP program which will take such an S-expression and perform some useful operation on it, such as determining the value of an algebraic expression. We need some procedures for distinguishing, decomposing, and constructing S-expressions. 
The predicate ATOM, when applied to an S-expression, produces true when given an atom and false otherwise. The empty list is considered to be an atom. The predicate NULL is true of only the empty list; its argument need not be a list, but may be any S-expression. The predicate NUMBERP is true of numbers and false of atomic symbols and lists. The predicate EQ, when applied to two atomic symbols, is true if the two atomic symbols are identical. It is false when applied to an atomic symbol and any other S-expression. (We have not defined EQ on two lists yet; this will not become important, or even meaningful, until we discuss side effects.) 
The decomposition operators for lists are traditionally called CAR and COR for historical reasons. [LISP History] CAR extracts the first element of a list, while COR produces a list containing all elements but the first. Because compositions of CAR and CDR are commonly used in LISP, an abbreviation is provided: all the C's and R's in the middle can be squeezed out. For example, "(CDR (CDR (CAR (CDR X))))" can be written as "(CDDADR X)". 
The construction operator CONS, given an S-expression and a list, produces a new list whose car is the S-expression and whose cdr is the list. The operator LIST can take any number of arguments (a special feature), and produces a list of its arguments. 
We can now write some interesting programs in LISP to deal with S-expressions. For example, we can write a predicate EQUAL, which determines whether two S-expressions have the same CAR-CDR structure: 


(DEFINE (EQUAL X Y)
           (COND ((NUMBERP X)
                  (COND ((NUMBERP Y) (= X Y))
                        (T NIL)))
                 ((ATOM X) (EQ X Y))
                 ((ATOM Y) NIL)
                 ((EQUAL (CAR X) (CAR Y))
                  (EQUAL (COR X) (CDR Y)))))

Here we have used the standard names T and NIL to represent true and false. (Traditionally NIL is also considered to be the empty list, but we will avoid this here, writing "()" for the empty list.) 
Because LISP programs are represented as LISP data structures (S-expressions), there is a difficulty with representing constants. For example, suppose we want to determine whether or not the value of the variable x is the atomic symbol "FOO". We might try writing:

(EQ X FOO)

This doesn't work. The occurrence of "FOO" does not refer to the atomic symbol FOO as a constant; it is treated as a variable, just as "x" is. 
The essential problem is that we want to be able to write any S-expression as a constant in a program, but some S-expressions must be used to represent other things, such as variables and procedure invocations. To solve this problem we invent a new notation: (QUOTE x) in a program represents the constant S-expression x. {Note QUOTE Mapping) Thus we can write our test as "(EQ X (QUOTE FOO))". Similarly, 

(EQUAL X (LIST Y Z))

constructs a list from the values of y and z, and compares the result to the value of x, while

(EQUAL X (QUOTE (LIST Y Z))) 

compares the value of x to the constant S-expression "(LIST Y Z)". Because the QUOTE Construction is used so frequently in LISP, we use an abbreviated notation: "'FOO" is equivalent to "(QUOTE FOO)". This is only a notational convenience; the two notations denote the same S-expression. (S-expressions are not character strings, but data objects with a certain structure. We use character strings to notate S-expressions on paper, but we can use other notations as well, such as little boxes and arrows. We can and do allow several different character strings to denote the same S-expression.) 


## An Interpreter for LISP Recursion Equations

We now have enough machinery to begin our examination of the genetic history of LISP. We first present a complete interpreter for LISP recursion equations. The language interpreted is a dialect of LISP which allows nо free variables except for names of primitive or defined procedures, and no definitions of procedures within other procedures.
The driver loop reads in definitions of procedures of the form: 

(DEFINE (F A B C ...) <expression in A B C ... and F G H ...>)

and saves them. It can also read in requests to apply some defined procedure to some arguments (or, more generally, to evaluate any expression), in which case it prints the resulting value. An expression may consist of variable references, constants (numbers and quoted S-expressions), procedure calls, and conditional expressions (COND). The defined procedures may refer to each other and to initially supplied primitive procedures (such as CAR, CONS, etc.). Definitions may contain "forward references", as long as all necessary definitions are present at the time of a request for computation. The interpreter itself is presented here as a set of such definitions, and so is meta-circular. 
The language is intended to be evaluated in applicative order; that is, all arguments to a procedure are fully evaluated before an attempt is made to apply the procedure to the arguments. (It is necessary to state this explicitly here, as it is not inherent in the form of the meta-circular definition. See [Reynolds] for an explication of this problem.) The driver loop (see Figure 1) is conceptually started by a request to invoke DRIVER with no arguments. Its task is to first print the message "LITHP ITH LITHTENING" (a tradition of sorts) and then invoke DRIVER-LOOP. The expression <THE-PRIMITIVE-PROCEDURES> is intended to represent a constant list structure, containing definitions of primitive procedures, to be supplied to DRIVER-LOOP. 

```lisp
(DEFINE (DRIVER)
        (DRIVER-LOOP <THE-PRIMITIVE-PROCEDURES> (PRINT '|LITHP TIH LITHTENING|)

(DEFINE (DRIVER-LOOP PROCEDURES HUNOZ)
        (DRIVER-LOOP1-PROCEDURES (READ)))

(DEFINE (DRIVER-LOOP-1 PROCEDURES FORM)
        (COND ((ATOM FORM)
               (DRIVER-LOOP PROCEDURES (PRNIT (EVAL FORM '() PROCEDURES))))
              ((EQ (CAR FORM) 'DEFINE)
               (DRIVER-LOOP (BIND (LIST (CAADR FORM)
                                  (LIST (LIST (CDADR FORM) (CADR FORM)))
                                  PROCEDURES)
                            (PRINT (CAADR FORM)))))
              (T (DRIVER-LOOP PROCEDURES (PRINT (EVAL FORM '() PROCEDURES))))))
Figure 1
Top Level Driver Loop for a Recursion Equations Interprete
```

DRIVER-LOOP reads an S-expression from the input stream and passes it, along with the current procedure definitions, to DRIVER-LOOP-1. This procedure in turn determines whether the input S-expression is a definition. If it is, then it uses BIND (described below) to produce an augmented set of procedure definitions, prints the name of the defined procedure, and calls DRIVER-LOOP to repeat the process. The augmented set of procedures is passed to DRIVER-LOOP, and so the variable PROCEDURES always contains all the accumulated definitions ever read. If the input 
input S-expression is not a definition, then it is given to the evaluator EVAL, whose purpose is to determine the values of expressions. {Note Value Quibble) The set of currently defined procedures is also passed to EVAL. 
The process carried on by the driver loop is often called the "top level"; all user programs and requests are run "under" it. The growing set of procedure definitions is called the "top-level environment"; this environment changes in the course of the user interaction, and contains the state of the machine as perceived by the user. It is within this environment that user programs are executed. 

```lisp
(DEFINE (EVAL EXP ENV PROCEDURES)
        (COND ((ATOM EXP)
               (COND ((EQ EXP 'NIL) 'NIL)
                     ((EQ EXP 'T) 'T)
                     ((NUMBERP EXP) EXP)
                     (T (VALUE EXP ENV))))
              ((EQ (CAR EXP) 'QUOTE)
               (CADR EXP))
              ((EQ (CAR EXP) 'COND)
               (EVCOND (COR EXP) ENV PROCEDURES))
              (T (APPLY (VALUE (CAR EXP) PROCEDURES)
                        (EVLIS (CDR EXP) ENV PROCEDURES)
                        PROCEDURES))))

(DEFINE (APLY FUN ARGS PROCEDURES)
        (COND ((PRIMOP FUN) (PRIMOP-APPLY FUN ARGS))
              (T (EVAL (CADR FUN)
                       (BIND (CAR FUN) ARGS '())
                       PROCEDURES))))

(DEFINE (ECOND CLAUSES ENV PROCEDURES)
        (COND ((NULL CLAUSES) (ERROR))
              ((EVAL (CAAR CLAUSES) ENV PROCEDURES)
               (EVAL (CADAR CLAUSES) ENV PROCEDURES))
              (T (EVCOND (CDR CLAUSES) ENV PROCEDURES))))

(DEFINE (EVLIS ARGLIST ENV PROCEDURES)
        (COND ((NULL ARGLIST) '())
              (T (CONS (EVAL (CAR ARGLIST) ENV PROCEDURES)
                       (EVLIS (CDR ARGLIST) ENV PROCEDURES)))))

Figure 2
Evaluator for a Recursion Equations Interpreter
```

The evaluator proper (see Figure 2) is divided into two conceptual components: EVAL and APPLY. EVAL classifies expressions and directs their evaluation. Simple expressions (such as constants and variables) can be evaluated directly. For the complex case of procedure invocations (technically called "combinations"), EVAL looks up the procedure definition, recursively evaluates the arguments (using EVLIS), and then calls APPLY. APPLY classifies procedures and directs their application. Simple procedures (primitive operators) are applied directly. For the complex case of user-defined procedures, APPLY uses BIND to build an environment, a kind of symbol table, associating the formal parameters from the procedure definition with the actual argument values provided by EVAL. The body of the procedure definition is then passed to EVAL, along with the environment just constructed, which is used to determine the values of variables occurring in the body. 
In more detail, EVAL is a case analysis on the structure of the S-expression EXP. If it is an atom, there are several subcases. The special atoms T and NIL are defined to evaluate to T and NIL (this is strictly for convenience, because they are used as truth values). Similarly, for convenience numeric atoms evaluate to themselves. (These cases could be eliminated by requiring the user to write lots of QUOTE forms: 'T, 'NIL, '43, etc. This would have been quite inconvenient in early LISP, before notation had been introduced; one would have had to write (QUOTE 43), etc.) Atomic symbols, however, encode variables; the value associated with that symbol is extracted from the environment ENV using the function VALUE (see below). 
If the expression to be evaluated is not atomic, then it may be a QUOTE form, a COND form, or a combination. For a QUOTE form, EVAL extracts the S-expression constant using CADR. Conditionals are handled by EVCOND, which calls EVAL on a predicate expression; if the predicate is true, EVCOND evaluates the corresponding result expression (by calling EVAL, of course); if the predicate is false, EVCOND calls itself to test the predicate of the next clause of the COND body. For combinations, the procedure is obtained, the arguments evaluated the arguments evaluated (using EVLIS), and APPLY called as described earlier. Notice that VALUE is used to get the procedure definition from the set PROCEDURES; we can do this because, as an engineering trick, we arrange for ENV and PROCEDURES to have the same structure, because they are both symbol tables. 
EVLIS is a simple recursive function which calls EVAL on successive arguments in ARGLIST and produces a list of the values in order. 
APPLY distinguishes two kinds of procedures: primitive and user-defined. For now we avoid describing the precise implementation of primitive procedures by assuming the existence of a predicate PRIMOP which is true only of primitive procedures, and a function PRIMOP-APPLY which deals with the application of such primitive procedures. (See {Note Primitive Operators} for the details of a possible implementation of PRIMOP and PRIMOP-APPLY.) We consider primitive 
primitive procedures to be a kind of atomic S-expression other than numbers and atomic symbols; we define no particular written notation for them here. However, primitive procedures are not to be confused with the atomic symbols used as their names. The result of (VALUE 'CAR PROCEDURES) is not the atomic symbol CAR, but rather some bizarre object which is meaningful only to PRIMOP-APPLY. 
User-defined procedures are represented here as lists. These lists are constructed by DRIVER-LOOP-1. The car of the list is the list of formal parameters, and the cadr is the body of the definition. 

```lisp
(DEFINE (BIND VARS ARGS ENV)
        (COND ((= (LENGTH VARS) (LENGTH ARGS))
               (CONS (CONS VARS ARGS) ENV))
              (T (ERROR))))

(DEFINE (VALUE NAME ENV)
        (VALUE1 NAME (LOOKUP NAME ENV)))

(DEFINE (VALUE1 NAME SLOT)
        (COND ((EQ SLOT '&UNBOUND) (ERROR))
              (T (CAR SLOT))))

(DEFINE (LOOKUP NAME ENV)
        (COND ((NULL ENV) '&UNBOUND)
              (T (LOOKUP1 NAME (CAAR ENV) (CDAR ENV) ENV))))

(DEFINE (LOOKUP1 NAME VARS VALS ENV)
        (COND ((NULL VARS) (LOOKUP NAME (CDR ENV)))
              ((EQ NAME (CAR VARS)) VALS)
              (T (LOOKUP1 NAME (CDR VARS) (CDR VALS) ENV))))

Figure 3
Utility Routines for Maintaining Environments
```

The interpreter uses several utility procedures for maintaining symbol tables (see Figure 3). A symbol table is represented as a list of buckets; each bucket is a list whose car is a list of names and whose cdr is a list of corresponding values. {Note This ain't A-lists) If a variable name occurs in more than one bucket, the leftmost such bucket has priority; in this way new symbol definitions added to the front of the list can supersede old ones. 
BIND takes a list of names, a list of values, and a symbol table, and produces a new symbol table which is the old one augmented by an extra bucket containing the new set of associations. (It also performs a useful error check LENGTH returns the length of a list.) 
VALUE is essentially an interface to LOOKUP. We define it because later, in Part Three, we will want to use different versions of VALUE1 without changing the underlying algorithm in LOOKUP. The check for &UNBOUND catches incorrect references to undefined variables. 
LOOKUP takes a name and a symbol table, and returns that portion of a bucket whose car is the associated value. (This definition will be more useful later than one in which the value itself is returned.) 
Note carefully the use of the variable PROCEDURES in the interpreter. When DRIVER-LOOP-1 calls EVAL it passes the current list of defined procedures (both primitive and user-defined). DRIVER-LOOP-1 is the only routine which augments the value of PROCEDURES, and this value is only used in EVAL, when it is passed to VALUE. However, all of the routines APPLY, EVCOND, and EVLIS have to know about PROCEDURES, and dutifully pass it along so that it may be eventually used by EVAL. The set of definitions must be passed along because there is no provision for free variables or side effects; there is no way to have "memory" or "state" other than in passed variables. The absence of free variables effectively causes language to be referentially transparent. However, we sense a disturbing lack of modularity in the use of PROCEDURES (and, to a lesser extent, in the use of ENV look at EVCOND and EVLIS). We will return to this point later.
Our recursion equations language has no special iteration or looping constructs, such as the Algol for statement or the FORTRAN DO loop. All loops are constructed by arranging for recursive procedures to call themselves or each other. For example, EVCOND (see Figure 2) iterates over the clauses of a COND by calling itself on successive "tails" of the list of clauses. Now such recursive calls may strike the reader familiar with other languages (such as Algol, FORTRAN, PL/I, etc.) on an intuitive level as being rather inefficient for implementing real programs. Even granted that calls might be made fast, they would seem to consume space in the form of return addresses and other control information. Examination of the recursion equations evaluator will show, however, that this phenomenon does not have to occur. This is because no extra information is saved if there is nothing left to do on return from a recursive call. See [SCHEME] and [Debunking] for a more thorough discussion of this.


# Part One - Variable Scoping Disciplines

## Procedures as Data




























## Local Procedures
## Lexical Scoping
## Top Levels versus Referential Transparency
# Part Two - State
## Decomposition of State
## Side Effects and Local State
## Side Effects in the Interpreter
## Equipotency of SETQ and RPLACA
## Side Effects and Equality
## Dynamic Scoping as a State-Decomposition Discipline
# Summary
# Acknowledgements
# Notes
## {Can George do Better?}
## {Debugging}
## {Driver Loop with Side Effects}
## {EVALQUOTE }
## {Gaussian}
## {LABELS}
## {LABELS with Side Effects} *
## {Primitive Operators}
## {PROGN Wizardry )
## {QUOTE Mapping}
## {QUOTE Shafts the Compiler}
## {RPLACA Can Alter CAR Instead}
## {S-expression Postulates and Notation}
## {This ain't A-lists}
## {Value Quibble}
## {Weber}
## {Y-operator}
# References
